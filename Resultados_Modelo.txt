C:\Users\JB\anaconda3\envs\detectron_env\python.exe C:/Users/JB/IdeaProjects/Detectron/train.py
[09/25 18:21:05 d2.engine.defaults]: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
    )
    (mask_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (mask_fcn1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn4): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
WARNING [09/25 18:21:05 d2.data.datasets.coco]: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[09/25 18:21:05 d2.data.datasets.coco]: Loaded 35 images in COCO format from train_cats.json
[09/25 18:21:05 d2.data.build]: Removed 0 images with no usable annotations. 35 images left.
[09/25 18:21:05 d2.data.build]: Distribution of instances among all 1 categories:
|  category  | #instances   |
|:----------:|:-------------|
|    cat     | 54           |
|            |              |
[09/25 18:21:05 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[09/25 18:21:05 d2.data.build]: Using training sampler TrainingSampler
[09/25 18:21:05 d2.data.common]: Serializing 35 elements to byte tensors and concatenating them all ...
[09/25 18:21:05 d2.data.common]: Serialized dataset takes 0.06 MiB
Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (2, 1024) in the model! You might want to double check if this is expected.
Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.
Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.
Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.
Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (1, 256, 1, 1) in the model! You might want to double check if this is expected.
Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (1,) in the model! You might want to double check if this is expected.
Some model parameters or buffers are not found in the checkpoint:
roi_heads.box_predictor.bbox_pred.{bias, weight}
roi_heads.box_predictor.cls_score.{bias, weight}
roi_heads.mask_head.predictor.{bias, weight}
[09/25 18:21:06 d2.engine.train_loop]: Starting training from iteration 0
C:\Users\JB\anaconda3\envs\detectron_env\lib\site-packages\torch\functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  C:\cb\pytorch_1000000000000\work\aten\src\ATen\native\TensorShape.cpp:2895.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
[09/25 18:21:25 d2.utils.events]:  eta: 0:04:20  iter: 19  total_loss: 1.468  loss_cls: 0.6271  loss_box_reg: 0.1349  loss_mask: 0.6874  loss_rpn_cls: 0.001414  loss_rpn_loc: 0.01245  time: 0.3105  data_time: 0.2728  lr: 4.9953e-06  max_mem: 2762M
[09/25 18:21:32 d2.utils.events]:  eta: 0:04:19  iter: 39  total_loss: 1.355  loss_cls: 0.5437  loss_box_reg: 0.1054  loss_mask: 0.668  loss_rpn_cls: 0.0009547  loss_rpn_loc: 0.01123  time: 0.3051  data_time: 0.0343  lr: 9.9902e-06  max_mem: 2762M
[09/25 18:21:38 d2.utils.events]:  eta: 0:04:13  iter: 59  total_loss: 1.165  loss_cls: 0.4012  loss_box_reg: 0.1102  loss_mask: 0.639  loss_rpn_cls: 0.0009035  loss_rpn_loc: 0.01261  time: 0.3083  data_time: 0.0612  lr: 1.4985e-05  max_mem: 2762M
[09/25 18:21:43 d2.utils.events]:  eta: 0:04:07  iter: 79  total_loss: 1.07  loss_cls: 0.277  loss_box_reg: 0.1579  loss_mask: 0.6045  loss_rpn_cls: 0.001916  loss_rpn_loc: 0.01112  time: 0.3014  data_time: 0.0194  lr: 1.998e-05  max_mem: 2762M
[09/25 18:21:50 d2.utils.events]:  eta: 0:03:59  iter: 99  total_loss: 0.8691  loss_cls: 0.1966  loss_box_reg: 0.1132  loss_mask: 0.546  loss_rpn_cls: 0.001601  loss_rpn_loc: 0.01119  time: 0.3025  data_time: 0.0600  lr: 2.4975e-05  max_mem: 2763M
[09/25 18:21:55 d2.utils.events]:  eta: 0:03:55  iter: 119  total_loss: 0.7935  loss_cls: 0.1569  loss_box_reg: 0.11  loss_mask: 0.4758  loss_rpn_cls: 0.00231  loss_rpn_loc: 0.01842  time: 0.2972  data_time: 0.0102  lr: 2.997e-05  max_mem: 2763M
[09/25 18:22:02 d2.utils.events]:  eta: 0:03:50  iter: 139  total_loss: 0.7255  loss_cls: 0.1252  loss_box_reg: 0.1131  loss_mask: 0.4289  loss_rpn_cls: 0.003793  loss_rpn_loc: 0.01144  time: 0.3037  data_time: 0.0895  lr: 3.4965e-05  max_mem: 2763M
[09/25 18:22:08 d2.utils.events]:  eta: 0:03:46  iter: 159  total_loss: 0.6562  loss_cls: 0.106  loss_box_reg: 0.09919  loss_mask: 0.3855  loss_rpn_cls: 0.00128  loss_rpn_loc: 0.009463  time: 0.3011  data_time: 0.0181  lr: 3.996e-05  max_mem: 2763M
[09/25 18:22:14 d2.utils.events]:  eta: 0:03:40  iter: 179  total_loss: 0.5693  loss_cls: 0.1028  loss_box_reg: 0.1115  loss_mask: 0.3372  loss_rpn_cls: 0.001186  loss_rpn_loc: 0.01303  time: 0.3018  data_time: 0.0511  lr: 4.4955e-05  max_mem: 2763M
[09/25 18:22:20 d2.utils.events]:  eta: 0:03:35  iter: 199  total_loss: 0.5401  loss_cls: 0.09422  loss_box_reg: 0.11  loss_mask: 0.2951  loss_rpn_cls: 0.001078  loss_rpn_loc: 0.01383  time: 0.3010  data_time: 0.0355  lr: 4.995e-05  max_mem: 2763M
[09/25 18:22:26 d2.utils.events]:  eta: 0:03:30  iter: 219  total_loss: 0.5089  loss_cls: 0.08034  loss_box_reg: 0.1097  loss_mask: 0.2633  loss_rpn_cls: 0.001332  loss_rpn_loc: 0.01314  time: 0.3045  data_time: 0.0822  lr: 5.4945e-05  max_mem: 2763M
[09/25 18:22:32 d2.utils.events]:  eta: 0:03:23  iter: 239  total_loss: 0.4532  loss_cls: 0.07954  loss_box_reg: 0.1148  loss_mask: 0.2414  loss_rpn_cls: 0.001048  loss_rpn_loc: 0.0145  time: 0.3032  data_time: 0.0385  lr: 5.994e-05  max_mem: 2763M
[09/25 18:22:39 d2.utils.events]:  eta: 0:03:18  iter: 259  total_loss: 0.4466  loss_cls: 0.08394  loss_box_reg: 0.1383  loss_mask: 0.2115  loss_rpn_cls: 0.001115  loss_rpn_loc: 0.008261  time: 0.3051  data_time: 0.0653  lr: 6.4935e-05  max_mem: 2763M
[09/25 18:22:45 d2.utils.events]:  eta: 0:03:13  iter: 279  total_loss: 0.4299  loss_cls: 0.0719  loss_box_reg: 0.1069  loss_mask: 0.1862  loss_rpn_cls: 0.001154  loss_rpn_loc: 0.01162  time: 0.3045  data_time: 0.0461  lr: 6.993e-05  max_mem: 2763M
[09/25 18:22:51 d2.utils.events]:  eta: 0:03:07  iter: 299  total_loss: 0.4184  loss_cls: 0.07353  loss_box_reg: 0.1202  loss_mask: 0.1653  loss_rpn_cls: 0.0008523  loss_rpn_loc: 0.01249  time: 0.3047  data_time: 0.0486  lr: 7.4925e-05  max_mem: 2763M
[09/25 18:22:57 d2.utils.events]:  eta: 0:03:01  iter: 319  total_loss: 0.4055  loss_cls: 0.05837  loss_box_reg: 0.1102  loss_mask: 0.1747  loss_rpn_cls: 0.001245  loss_rpn_loc: 0.01519  time: 0.3046  data_time: 0.0443  lr: 7.992e-05  max_mem: 2763M
[09/25 18:23:03 d2.utils.events]:  eta: 0:02:57  iter: 339  total_loss: 0.3294  loss_cls: 0.05199  loss_box_reg: 0.1052  loss_mask: 0.1525  loss_rpn_cls: 0.002058  loss_rpn_loc: 0.01548  time: 0.3055  data_time: 0.0472  lr: 8.4915e-05  max_mem: 2763M
[09/25 18:23:09 d2.utils.events]:  eta: 0:02:51  iter: 359  total_loss: 0.3476  loss_cls: 0.05668  loss_box_reg: 0.127  loss_mask: 0.1367  loss_rpn_cls: 0.00094  loss_rpn_loc: 0.009145  time: 0.3049  data_time: 0.0387  lr: 8.991e-05  max_mem: 2763M
[09/25 18:23:15 d2.utils.events]:  eta: 0:02:46  iter: 379  total_loss: 0.3082  loss_cls: 0.04579  loss_box_reg: 0.107  loss_mask: 0.1111  loss_rpn_cls: 0.0004647  loss_rpn_loc: 0.009101  time: 0.3049  data_time: 0.0448  lr: 9.4905e-05  max_mem: 2763M
[09/25 18:23:22 d2.utils.events]:  eta: 0:02:41  iter: 399  total_loss: 0.3067  loss_cls: 0.04868  loss_box_reg: 0.1006  loss_mask: 0.1191  loss_rpn_cls: 0.0005746  loss_rpn_loc: 0.01235  time: 0.3070  data_time: 0.0873  lr: 9.99e-05  max_mem: 2763M
[09/25 18:23:28 d2.utils.events]:  eta: 0:02:35  iter: 419  total_loss: 0.3131  loss_cls: 0.0412  loss_box_reg: 0.09909  loss_mask: 0.1221  loss_rpn_cls: 0.0005223  loss_rpn_loc: 0.01068  time: 0.3068  data_time: 0.0438  lr: 0.0001049  max_mem: 2763M
[09/25 18:23:34 d2.utils.events]:  eta: 0:02:30  iter: 439  total_loss: 0.2926  loss_cls: 0.04557  loss_box_reg: 0.1022  loss_mask: 0.1106  loss_rpn_cls: 0.000416  loss_rpn_loc: 0.009924  time: 0.3068  data_time: 0.0447  lr: 0.00010989  max_mem: 2763M
[09/25 18:23:42 d2.utils.events]:  eta: 0:02:25  iter: 459  total_loss: 0.3097  loss_cls: 0.05492  loss_box_reg: 0.1244  loss_mask: 0.113  loss_rpn_cls: 0.0002999  loss_rpn_loc: 0.01049  time: 0.3092  data_time: 0.0757  lr: 0.00011489  max_mem: 2763M
[09/25 18:23:48 d2.utils.events]:  eta: 0:02:20  iter: 479  total_loss: 0.2841  loss_cls: 0.04153  loss_box_reg: 0.1136  loss_mask: 0.106  loss_rpn_cls: 0.0005902  loss_rpn_loc: 0.01086  time: 0.3100  data_time: 0.0407  lr: 0.00011988  max_mem: 2763M
[09/25 18:23:54 d2.utils.events]:  eta: 0:02:14  iter: 499  total_loss: 0.2266  loss_cls: 0.03106  loss_box_reg: 0.07515  loss_mask: 0.09285  loss_rpn_cls: 0.0007695  loss_rpn_loc: 0.01528  time: 0.3101  data_time: 0.0316  lr: 0.00012488  max_mem: 2763M
[09/25 18:24:01 d2.utils.events]:  eta: 0:02:09  iter: 519  total_loss: 0.2917  loss_cls: 0.03784  loss_box_reg: 0.1184  loss_mask: 0.09909  loss_rpn_cls: 0.0002144  loss_rpn_loc: 0.01039  time: 0.3108  data_time: 0.0582  lr: 0.00012987  max_mem: 2763M
[09/25 18:24:07 d2.utils.events]:  eta: 0:02:04  iter: 539  total_loss: 0.2531  loss_cls: 0.03931  loss_box_reg: 0.07386  loss_mask: 0.09181  loss_rpn_cls: 0.0003295  loss_rpn_loc: 0.009263  time: 0.3102  data_time: 0.0384  lr: 0.00013487  max_mem: 2763M
[09/25 18:24:14 d2.utils.events]:  eta: 0:01:58  iter: 559  total_loss: 0.2485  loss_cls: 0.03611  loss_box_reg: 0.08404  loss_mask: 0.09212  loss_rpn_cls: 0.0002352  loss_rpn_loc: 0.01261  time: 0.3113  data_time: 0.0506  lr: 0.00013986  max_mem: 2763M
[09/25 18:24:20 d2.utils.events]:  eta: 0:01:53  iter: 579  total_loss: 0.2005  loss_cls: 0.03028  loss_box_reg: 0.05411  loss_mask: 0.09437  loss_rpn_cls: 0.0005971  loss_rpn_loc: 0.01063  time: 0.3114  data_time: 0.0441  lr: 0.00014486  max_mem: 2763M
[09/25 18:24:26 d2.utils.events]:  eta: 0:01:48  iter: 599  total_loss: 0.204  loss_cls: 0.03248  loss_box_reg: 0.06295  loss_mask: 0.09113  loss_rpn_cls: 0.000448  loss_rpn_loc: 0.0146  time: 0.3111  data_time: 0.0370  lr: 0.00014985  max_mem: 2763M
[09/25 18:24:33 d2.utils.events]:  eta: 0:01:42  iter: 619  total_loss: 0.2097  loss_cls: 0.03173  loss_box_reg: 0.05499  loss_mask: 0.08757  loss_rpn_cls: 0.0006746  loss_rpn_loc: 0.01183  time: 0.3124  data_time: 0.0798  lr: 0.00015485  max_mem: 2763M
[09/25 18:24:39 d2.utils.events]:  eta: 0:01:37  iter: 639  total_loss: 0.2135  loss_cls: 0.03556  loss_box_reg: 0.05733  loss_mask: 0.08938  loss_rpn_cls: 0.000357  loss_rpn_loc: 0.01503  time: 0.3123  data_time: 0.0436  lr: 0.00015984  max_mem: 2763M
[09/25 18:24:45 d2.utils.events]:  eta: 0:01:31  iter: 659  total_loss: 0.1895  loss_cls: 0.03159  loss_box_reg: 0.0522  loss_mask: 0.08432  loss_rpn_cls: 0.000128  loss_rpn_loc: 0.014  time: 0.3118  data_time: 0.0306  lr: 0.00016484  max_mem: 2763M
[09/25 18:24:51 d2.utils.events]:  eta: 0:01:26  iter: 679  total_loss: 0.1859  loss_cls: 0.02909  loss_box_reg: 0.0464  loss_mask: 0.07872  loss_rpn_cls: 0.0002771  loss_rpn_loc: 0.01033  time: 0.3113  data_time: 0.0258  lr: 0.00016983  max_mem: 2763M
[09/25 18:24:58 d2.utils.events]:  eta: 0:01:21  iter: 699  total_loss: 0.1826  loss_cls: 0.03152  loss_box_reg: 0.04151  loss_mask: 0.08358  loss_rpn_cls: 0.0002911  loss_rpn_loc: 0.01163  time: 0.3120  data_time: 0.0495  lr: 0.00017483  max_mem: 2763M
[09/25 18:25:04 d2.utils.events]:  eta: 0:01:15  iter: 719  total_loss: 0.1626  loss_cls: 0.02744  loss_box_reg: 0.04315  loss_mask: 0.0751  loss_rpn_cls: 0.0001313  loss_rpn_loc: 0.01144  time: 0.3123  data_time: 0.0185  lr: 0.00017982  max_mem: 2763M
[09/25 18:25:11 d2.utils.events]:  eta: 0:01:10  iter: 739  total_loss: 0.1772  loss_cls: 0.03068  loss_box_reg: 0.04289  loss_mask: 0.07898  loss_rpn_cls: 0.0002089  loss_rpn_loc: 0.01019  time: 0.3129  data_time: 0.0238  lr: 0.00018482  max_mem: 2763M
[09/25 18:25:17 d2.utils.events]:  eta: 0:01:05  iter: 759  total_loss: 0.1723  loss_cls: 0.02587  loss_box_reg: 0.03397  loss_mask: 0.08216  loss_rpn_cls: 0.0001897  loss_rpn_loc: 0.01375  time: 0.3126  data_time: 0.0404  lr: 0.00018981  max_mem: 2763M
[09/25 18:25:24 d2.utils.events]:  eta: 0:00:59  iter: 779  total_loss: 0.1683  loss_cls: 0.02664  loss_box_reg: 0.03757  loss_mask: 0.08344  loss_rpn_cls: 0.0002929  loss_rpn_loc: 0.007816  time: 0.3136  data_time: 0.0887  lr: 0.00019481  max_mem: 2763M
[09/25 18:25:30 d2.utils.events]:  eta: 0:00:54  iter: 799  total_loss: 0.1887  loss_cls: 0.02949  loss_box_reg: 0.03922  loss_mask: 0.07672  loss_rpn_cls: 7.602e-05  loss_rpn_loc: 0.01263  time: 0.3127  data_time: 0.0152  lr: 0.0001998  max_mem: 2763M
[09/25 18:25:36 d2.utils.events]:  eta: 0:00:48  iter: 819  total_loss: 0.1392  loss_cls: 0.02374  loss_box_reg: 0.03052  loss_mask: 0.07052  loss_rpn_cls: 0.0002523  loss_rpn_loc: 0.007966  time: 0.3125  data_time: 0.0571  lr: 0.0002048  max_mem: 2763M
[09/25 18:25:42 d2.utils.events]:  eta: 0:00:43  iter: 839  total_loss: 0.1728  loss_cls: 0.02521  loss_box_reg: 0.03167  loss_mask: 0.07388  loss_rpn_cls: 0.0001423  loss_rpn_loc: 0.009531  time: 0.3125  data_time: 0.0469  lr: 0.00020979  max_mem: 2763M
[09/25 18:25:48 d2.utils.events]:  eta: 0:00:37  iter: 859  total_loss: 0.1328  loss_cls: 0.02296  loss_box_reg: 0.02254  loss_mask: 0.06912  loss_rpn_cls: 8.921e-05  loss_rpn_loc: 0.008797  time: 0.3123  data_time: 0.0418  lr: 0.00021479  max_mem: 2763M
[09/25 18:25:54 d2.utils.events]:  eta: 0:00:32  iter: 879  total_loss: 0.1225  loss_cls: 0.01974  loss_box_reg: 0.02532  loss_mask: 0.06585  loss_rpn_cls: 0.000378  loss_rpn_loc: 0.0122  time: 0.3119  data_time: 0.0418  lr: 0.00021978  max_mem: 2763M
[09/25 18:26:00 d2.utils.events]:  eta: 0:00:27  iter: 899  total_loss: 0.1708  loss_cls: 0.02925  loss_box_reg: 0.0306  loss_mask: 0.07035  loss_rpn_cls: 0.0001619  loss_rpn_loc: 0.01181  time: 0.3120  data_time: 0.0609  lr: 0.00022478  max_mem: 2763M
[09/25 18:26:07 d2.utils.events]:  eta: 0:00:21  iter: 919  total_loss: 0.1466  loss_cls: 0.01873  loss_box_reg: 0.02445  loss_mask: 0.0735  loss_rpn_cls: 0.0002083  loss_rpn_loc: 0.01454  time: 0.3120  data_time: 0.0424  lr: 0.00022977  max_mem: 2763M
[09/25 18:26:12 d2.utils.events]:  eta: 0:00:16  iter: 939  total_loss: 0.1272  loss_cls: 0.02199  loss_box_reg: 0.02511  loss_mask: 0.06385  loss_rpn_cls: 0.0001754  loss_rpn_loc: 0.009021  time: 0.3110  data_time: 0.0097  lr: 0.00023477  max_mem: 2763M
[09/25 18:26:19 d2.utils.events]:  eta: 0:00:10  iter: 959  total_loss: 0.1461  loss_cls: 0.02103  loss_box_reg: 0.02499  loss_mask: 0.0707  loss_rpn_cls: 0.0002545  loss_rpn_loc: 0.01153  time: 0.3122  data_time: 0.1039  lr: 0.00023976  max_mem: 2763M
[09/25 18:26:25 d2.utils.events]:  eta: 0:00:05  iter: 979  total_loss: 0.1305  loss_cls: 0.01977  loss_box_reg: 0.02541  loss_mask: 0.06457  loss_rpn_cls: 0.0002703  loss_rpn_loc: 0.008102  time: 0.3120  data_time: 0.0298  lr: 0.00024476  max_mem: 2763M
[09/25 18:26:33 d2.utils.events]:  eta: 0:00:00  iter: 999  total_loss: 0.1157  loss_cls: 0.02292  loss_box_reg: 0.02389  loss_mask: 0.06357  loss_rpn_cls: 0.0004332  loss_rpn_loc: 0.01011  time: 0.3126  data_time: 0.0302  lr: 0.00024975  max_mem: 2763M
[09/25 18:26:33 d2.engine.hooks]: Overall training speed: 998 iterations in 0:05:11 (0.3126 s / it)
[09/25 18:26:33 d2.engine.hooks]: Total training time: 0:05:12 (0:00:00 on hooks)
WARNING [09/25 18:26:33 d2.data.datasets.coco]: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[09/25 18:26:33 d2.data.datasets.coco]: Loaded 5 images in COCO format from test_cats.json
[09/25 18:26:33 d2.data.build]: Distribution of instances among all 1 categories:
|  category  | #instances   |
|:----------:|:-------------|
|    cat     | 8            |
|            |              |
[09/25 18:26:33 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/25 18:26:33 d2.data.common]: Serializing 5 elements to byte tensors and concatenating them all ...
[09/25 18:26:33 d2.data.common]: Serialized dataset takes 0.01 MiB
WARNING [09/25 18:26:33 d2.engine.defaults]: No evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.

Process finished with exit code 0
